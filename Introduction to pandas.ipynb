{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to pandas\n",
    "\n",
    "This notebook will introduce you to the [`pandas`](https://pandas.pydata.org/) data analysis library and demonstrate how to inspect, sort, filter, group and aggregate a data set.\n",
    "\n",
    "The data for this exercise will be a CSV of [USA TODAY's opening-day MLB salaries](https://www.usatoday.com/sports/mlb/salaries/).\n",
    "\n",
    "If you're completely new to Python or your syntax is rusty, it might be useful to [keep this notebook open in a new tab](Python%20syntax%20cheat%20sheet.ipynb) as a reference.\n",
    "\n",
    "#### Ssession outline\n",
    "- [Using Jupyter notebooks](#Using-Jupyter-notebooks)\n",
    "- [Import pandas](#Import-pandas)\n",
    "- [Load data into a data frame](#Load-data-into-a-data-frame)\n",
    "- [Inspect the data](#Inspect-the-data)\n",
    "- [Sort the data](#Sort-the-data)\n",
    "- [Filter the data](#Filter-the-data)\n",
    "- [Group and aggregate the data](#Group-and-aggregate-the-data)\n",
    "- [Export to CSV](#Export-to-CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Jupyter notebooks\n",
    "\n",
    "There are many ways to write and run Python code on your computer. One way -- the method we're using today -- is to use [Jupyter notebooks](https://jupyter.org/), which run in your browser and allow you to intersperse documentation with your code. They're handy for bundling your code with a human-readable explanation of what's happening at each step. Check out some examples from the [L.A. Times](https://github.com/datadesk/notebooks) and [BuzzFeed News](https://github.com/BuzzFeedNews/everything#data-and-analyses).\n",
    "\n",
    "**To add a new cell to your notebook**: Click the + button in the menu.\n",
    "\n",
    "**To run a cell of code**: Select the cell and click the \"Run\" button in the menu, or you can press Shift+Enter.\n",
    "\n",
    "**One common gotcha**: The notebook doesn't \"know\" about code you've written until you've _run_ the cell containing it. For example, if you define a variable called `my_name` in one cell, and later, when you try to access that variable in another cell but get an error that says `NameError: name 'my_name' is not defined`, the most likely solution is to run (or re-run) the cell in which you defined `my_name`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import pandas\n",
    "\n",
    "Before you can use the functionality of `pandas`, a third-party library installed separately from Python, you need to _import_ it. The convention is to import the library under an alias that's easier to type: `as pd`.\n",
    "\n",
    "Run this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change a display setting\n",
    "\n",
    "Run the next cell to change a setting that displays big numbers in scientific notation by default. (Unless scientific notation is your jam, in which case _avoid_ running the next cell.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html\n",
    "pd.options.display.float_format = '{:20,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data into a data frame\n",
    "\n",
    "Before you can start poking at a data file, you need to load the data into a pandas _data frame_, which is sort of like a virtual spreadsheet with columns and rows.\n",
    "\n",
    "You can load many different types of data files into a data frame, including CSVs (and other delimited text files), Excel files, JSON [and more](https://www.cbtnuggets.com/blog/2018/10/14-file-types-you-can-import-into-pandas/). ([Here's a notebook](https://github.com/ireapps/cfj-2018/blob/master/reference/Importing%20data%20into%20pandas.ipynb) demonstrating how to import some different data files, including live data from the Internet!)\n",
    "\n",
    "For today, we'll focus on importing the MLB salary data using a pandas method called [`read_csv()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html). There are a ton of options you can supply when you read in the data file, but at minimum, you need to tell the method _where_ the file lives, which means you need to supply the path to the data file as a Python _string_ (some text enclosed in single or double quotes). The file is called `mlb-salaries-2023.csv`, and it is located in the same directory as this notebook file, so we don't need to specify a longer path.\n",
    "\n",
    "As we import the data, we'll also _assign_ the results of the loading operation to a new variable we have decided to call _df_ (short for data frame -- easy to type, plus you'll see this pattern a lot when Googling around for help).\n",
    "\n",
    "👉 [Click here for more information on Python variables](Python%20syntax%20cheat%20sheet.ipynb#Variable-assignment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('mlb-salaries-usa-today-2024.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a human sentence: \"Go to the pandas library that we imported earlier as something called `pd` and use its `read_csv()` method to import a file called `mlb-salaries-usa-today-2024.csv` into a data frame -- and assign the results of that operation to a new variable called `df`.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the data\n",
    "\n",
    "Let's take a look at what we've got using a few built-in methods and attributes of a pandas data frame:\n",
    "- `df.head()` will display the first five records (or, if you prefer, you can specify a number, e.g., `df.head(10)`)\n",
    "- `df.tail()` will display the last five records (or, if you prefer, you can specify a number, e.g., `df.tail(10)`)\n",
    "- `df.describe()` will compute summary stats on numeric columns\n",
    "- `df.sample()` will return a randomly selected record (or, if you prefer, you specify a number, e.g., `df.sample(5)`\n",
    "- `df.shape` will tell you how many columns, how many rows\n",
    "- Using the Python function `len()` is another way to get a record count: `len(df)`\n",
    "- `df.dtypes` will list the column names and tell you what kind of data is in each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the data\n",
    "\n",
    "To sort a data frame, use the `sort_values()` method. At a minimum, you need to tell it which column to sort on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sort_values('salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sort descending, you need to pass in another argument to the `sort_values()` method: `ascending=False`. Note that the boolean value is _not_ a string, so it's not contained in quotes, and only the initial letter is capitalized. (If you are supplying multiple arguments to a function or method, separate them with commas.)\n",
    "\n",
    "👉 [Click here for more information on Python booleans](Python%20syntax%20cheat%20sheet.ipynb#Booleans)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sort_values('salary', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use a process called \"method chaining\" to perform multiple operations in one line. If, for instance, we wanted to sort the data frame by salary descending and inspect the first 5 records returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sort_values('salary', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can sort by multiple columns by passing in a _list_ of column names rather than the name of a single column. A list is a collection of items enclosed within square brackets `[]`.\n",
    "\n",
    "👉 [Click here for more information on Python lists](Python%20syntax%20cheat%20sheet.ipynb#Lists).\n",
    "\n",
    "To sort first by `salary`, then by `team`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sort_values(['salary', 'team']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify the sort order (descending vs. ascending) for each sort column by passing another list to the `ascending` keyword with `True` and `False` items corresponding to the position of the columns in the first list. \n",
    "\n",
    "For example, to sort by `salary` descending, then by `team` ascending:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sort_values(['salary', 'team'], ascending=[False, True]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `False` goes with `salary` and the `True` with `team` because they're in the same position in their respective lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One other note: Despite all of this sorting we've been doing, the original `df` data frame is unchanged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's because we haven't \"saved\" the results of those sorts by assigning them to a new variable. Typically, if you want to preserve a sort (or any other kind of manipulation), you'd would assign the results to a new variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted_by_team = df.sort_values('team')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted_by_team.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✍️ Your turn\n",
    "\n",
    "In the cells below, practice sorting the `df` data frame:\n",
    "- By `name`\n",
    "- By `position` descending\n",
    "- By `salary` descending, then by `position` ascending, and save the results to a new variable called `sorted_by_salary_then_position`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the data\n",
    "\n",
    "Let's go over two different kinds of filtering:\n",
    "\n",
    "- Column filtering: Grabbing one or more columns of data to look at, like passing column names to a `SELECT` statement in SQL.\n",
    "- Row filtering: Looking at a subset of your data that matches some criteria, like the crieria following a `WHERE` statement in SQL. (For instance, \"Show me all records in my data frame where the value in the `team` column is \"Arizona\".)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column filtering\n",
    "\n",
    "To access the values in a single column of data, you can use \"dot notation\" as long as the column name doesn't have spaces or other special characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise, use \"bracket notation\" with the name of the column as a string.\n",
    "\n",
    "This is equivalent to the previous command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['team']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you access a single column in your data frame, you're getting back something called a [`Series`](https://pandas.pydata.org/docs/reference/api/pandas.Series.html) object (as opposed to a `DataFrame` object).\n",
    "\n",
    "One of the methods you can call on a Series is `unique()`, which shows you each unique value in the column. Let's do that with the `team` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['team'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we just did is the equivalent of dragging the \"team\" column name into the \"rows\" area of a spreadsheet pivot table, or, in SQL,\n",
    "\n",
    "```sql\n",
    "SELECT DISTINCT TEAM\n",
    "FROM mlb\n",
    "```\n",
    "\n",
    "You can also count up a total for each value using the `value_counts()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['team'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For numeric columns, you can call methods on that Series to compute basic summary stats:\n",
    "- `min()` to get the lowest value\n",
    "- `max()` to get the greatest value\n",
    "- `median()` to get the median\n",
    "- `mean()` to get the average\n",
    "- `mode()` to get the most common value\n",
    "\n",
    "Check it out for the `SALARY` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['salary'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['salary'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['salary'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['salary'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['salary'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select multiple columns in your data frame, use bracket notation but pass in a _list_ of column names instead of just one. To make things clearer, you could break this out into two steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns_we_care_about = ['team', 'salary']\n",
    "df[columns_we_care_about]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Row filtering\n",
    "\n",
    "To make things maximally confusing, you _also_ use bracket notation for row filtering. Except in this case, instead of dropping the name of a column (or a list of column names) into the brackets, you hand it a _logical condition_ that resolves to `True` or `False`.\n",
    "\n",
    "Let's filter our data to see players who make more than $1 million (in other words, return rows of data where the value in the `salary` column is greater than 1000000):\n",
    "\n",
    "(The equivalent SQL statement would be:\n",
    "```sql\n",
    "SELECT *\n",
    "FROM mlb\n",
    "WHERE SALARY > 1000000\n",
    "```\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df['salary'] > 1000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For many filters, you'll use Python's comparison operators:\n",
    "- `>` greater than\n",
    "- `>=` greater than or equal to\n",
    "- `<` less than\n",
    "- `<=` less than or equal to\n",
    "- `==` equal to\n",
    "- `!=` not equal to\n",
    "\n",
    "#### Multiple filter conditions\n",
    "\n",
    "What if you want to use multiple filtering conditions? There is a way, but it usually makes more sense -- and is much easier for your colleagues and your future self to think about and debug -- to _save_ the results of each filtering operation by assigning the results to a new variable, then filter _the filtered data frame_ again instead of the original data frame.\n",
    "\n",
    "For example, if you wanted to look at Colorado Rockies players who make more than $1 million, you might do something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rockies = df[df['team'] == 'Colorado']\n",
    "rockies_over_1m = rockies[rockies['salary'] > 1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rockies_over_1m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👉 [Check out some other filtering operations here]()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✍️ Your turn\n",
    "\n",
    "In the cells below, practice filtering:\n",
    "- Column filtering: Select the `name` column\n",
    "- Column filtering: Select the `name` and `team` columns\n",
    "- Row filtering: Filter the rows to return only players who make the league minimum (by definition, the lowest number in the `salary` column)\n",
    "- Row filtering: Filter the rows to return only catchers (`C`) who make at least $750,000\n",
    "- BONUS: Filter the rows to return only players for the Chicago White Sox, then use method chaining to order the results by `salary` descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group and aggregate the data\n",
    "\n",
    "Data frames have a `groupby` method for grouping and aggregating data, similar to what you might do in a pivot table or a `GROUP BY` statement in SQL. (They also have a [`pivot_table` method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html), which can be homework for you to research.)\n",
    "\n",
    "Let's say we wanted to see the top 10 teams by payroll. In other words, we want to:\n",
    "- Group the data by the `team` column: `groupby()`\n",
    "- Add up the records in each group: `sum()`\n",
    "- Sort the results by `salary` descending: `sort_values()`\n",
    "- Take only the top 10 results: `head(10)`\n",
    "\n",
    "Calling the `groupby()` method without telling it what to do with the grouped records isn't super helpful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby('team')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, it's basically telling us that it has successfully grouped the records -- now what? Using method chaining, describe what you would like to _do_ with the numeric columns once you've grouped the data. Let's start with `sum()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby('team').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ope! It's summing _every_ column, not just `salary`.\n",
    "\n",
    "To deal with this, use column filtering to select the two columns we're interested in -- `team` for grouping and `salary` for summing -- and _then_ tack on the `groupby` statement, etc.\n",
    "\n",
    "(Remember: To select columns from a data frame, use bracket notation and hand it a _list_ of column names.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['team', 'salary']].groupby('team').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bang bang. Now, using method chaining, let's sort by `salary` descending and look at just the top 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['team', 'salary']].groupby('team').sum().sort_values('salary', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use aggregation methods other than `sum()` -- `mean()` and `median()`, for instance -- or you can use [the `agg()` method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html) to specify one or more aggregation methods to apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['team', 'salary']].groupby('team').median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['team', 'salary']].groupby('team').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['team', 'salary']].groupby('team').agg(['sum', 'mean', 'median'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✍️ Your turn\n",
    "\n",
    "In the cells below, practice grouping data:\n",
    "- What's the median salary for each position? Group the data by `position` and aggregate by `median()`, then sort by `salary` descending\n",
    "- What's the average salary on each team? Group the data by `team` and aggregate by `sum()`, then sort by `salary` descending\n",
    "- What else?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to CSV\n",
    "\n",
    "To export a dataframe to a delimited text file, use the [`to_csv()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html) method. If you don't want to include the index numbers, specify `index=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('my-cool-data-frame.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
